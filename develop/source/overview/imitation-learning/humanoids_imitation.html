

<!DOCTYPE html>


<html lang="en" data-content_root="" >

  <head>
    <meta charset="utf-8" />
    <meta name="viewport" content="width=device-width, initial-scale=1.0" /><meta name="generator" content="Docutils 0.19: https://docutils.sourceforge.io/" />

    <title>Examples: Data Generation and Imitation Learning for Humanoids &#8212; Isaac Lab Documentation</title>
  
  
  
  <script data-cfasync="false">
    document.documentElement.dataset.mode = localStorage.getItem("mode") || "";
    document.documentElement.dataset.theme = localStorage.getItem("theme") || "";
  </script>
  <!--
    this give us a css class that will be invisible only if js is disabled
  -->
  <noscript>
    <style>
      .pst-js-only { display: none !important; }

    </style>
  </noscript>
  
  <!-- Loaded before other Sphinx assets -->
  <link href="../../../_static/styles/theme.css?digest=8878045cc6db502f8baf" rel="stylesheet" />
<link href="../../../_static/styles/pydata-sphinx-theme.css?digest=8878045cc6db502f8baf" rel="stylesheet" />

    <link rel="stylesheet" type="text/css" href="../../../_static/pygments.css" />
    <link rel="stylesheet" href="../../../_static/styles/sphinx-book-theme.css?digest=14f4ca6b54d191a8c7657f6c759bf11a5fb86285" type="text/css" />
    <link rel="stylesheet" type="text/css" href="../../../_static/twemoji.css" />
    <link rel="stylesheet" type="text/css" href="/opt/hostedtoolcache/Python/3.12.12/x64/lib/python3.12/site-packages/sphinxcontrib/icon/node_modules/@fortawesome/fontawesome-free/css/all.min.css" />
    <link rel="stylesheet" type="text/css" href="../../../_static/copybutton.css" />
    <link rel="stylesheet" type="text/css" href="../../../_static/custom.css" />
    <link rel="stylesheet" type="text/css" href="../../../_static/sphinx-design.4cbf315f70debaebd550c87a6162cf0f.min.css" />
  
  <!-- So that users can add custom icons -->
  <script src="../../../_static/scripts/fontawesome.js?digest=8878045cc6db502f8baf"></script>
  <!-- Pre-loaded scripts that we'll load fully later -->
  <link rel="preload" as="script" href="../../../_static/scripts/bootstrap.js?digest=8878045cc6db502f8baf" />
<link rel="preload" as="script" href="../../../_static/scripts/pydata-sphinx-theme.js?digest=8878045cc6db502f8baf" />

    <script data-url_root="../../../" id="documentation_options" src="../../../_static/documentation_options.js"></script>
    <script src="../../../_static/doctools.js"></script>
    <script src="../../../_static/sphinx_highlight.js"></script>
    <script src="https://unpkg.com/twemoji@latest/dist/twemoji.min.js"></script>
    <script src="../../../_static/twemoji.js"></script>
    <script src="/opt/hostedtoolcache/Python/3.12.12/x64/lib/python3.12/site-packages/sphinxcontrib/icon/node_modules/@fortawesome/fontawesome-free/js/all.min.js"></script>
    <script src="../../../_static/clipboard.min.js"></script>
    <script src="../../../_static/copybutton.js"></script>
    <script src="../../../_static/scripts/sphinx-book-theme.js?digest=5a5c038af52cf7bc1a1ec88eea08e6366ee68824"></script>
    <script src="../../../_static/design-tabs.js"></script>
    <script>DOCUMENTATION_OPTIONS.pagename = 'source/overview/imitation-learning/humanoids_imitation';</script>
    <link rel="icon" href="../../../_static/favicon.ico"/>
    <link rel="index" title="Index" href="../../../genindex.html" />
    <link rel="search" title="Search" href="../../../search.html" />
    <link rel="next" title="Augmented Imitation Learning" href="augmented_imitation.html" />
    <link rel="prev" title="Teleoperation and Imitation Learning with Isaac Lab Mimic" href="teleop_imitation.html" />
  <meta name="viewport" content="width=device-width, initial-scale=1"/>
  <meta name="docsearch:language" content="en"/>
  <meta name="docsearch:version" content="3.0.0" />
    <meta name="docbuild:last-update" content="Feb 26, 2026"/>
  </head>
  
  
  <body data-bs-spy="scroll" data-bs-target=".bd-toc-nav" data-offset="180" data-bs-root-margin="0px 0px -60%" data-default-mode="">

  
  
  <div id="pst-skip-link" class="skip-link d-print-none"><a href="#main-content">Skip to main content</a></div>
  
  <div id="pst-scroll-pixel-helper"></div>
  
  <button type="button" class="btn rounded-pill" id="pst-back-to-top">
    <i class="fa-solid fa-arrow-up"></i>Back to top</button>

  
  <dialog id="pst-search-dialog">
    
<form class="bd-search d-flex align-items-center"
      action="../../../search.html"
      method="get">
  <i class="fa-solid fa-magnifying-glass"></i>
  <input type="search"
         class="form-control"
         name="q"
         placeholder="Search..."
         aria-label="Search..."
         autocomplete="off"
         autocorrect="off"
         autocapitalize="off"
         spellcheck="false"/>
  <span class="search-button__kbd-shortcut"><kbd class="kbd-shortcut__modifier">Ctrl</kbd>+<kbd>K</kbd></span>
</form>
  </dialog>

  <div class="pst-async-banner-revealer d-none">
  <aside id="bd-header-version-warning" class="d-none d-print-none" aria-label="Version warning"></aside>
</div>

  
    <header class="bd-header navbar navbar-expand-lg bd-navbar d-print-none">
    </header>
  

  <div class="bd-container">
    <div class="bd-container__inner bd-page-width">
      
      
      
      <dialog id="pst-primary-sidebar-modal"></dialog>
      <div id="pst-primary-sidebar" class="bd-sidebar-primary bd-sidebar">
        

  
  <div class="sidebar-header-items sidebar-primary__section">
    
    
    
    
  </div>
  
    <div class="sidebar-primary-items__start sidebar-primary__section">
        <div class="sidebar-primary-item">

  
    
  

<a class="navbar-brand logo" href="../../../index.html">
  
  
  
  
  
    
    
      
    
    
    <img src="../../../_static/NVIDIA-logo-white.png" class="logo__image only-light" alt=""/>
    <img src="../../../_static/NVIDIA-logo-black.png" class="logo__image only-dark pst-js-only" alt=""/>
  
  
    <p class="title logo__title">Isaac Lab Documentation</p>
  
</a></div>
        <div class="sidebar-primary-item">
<nav class="bd-links bd-docs-nav">
    <div class="bd-toc-item navbar-nav">
      <ul class="nav bd-sidenav">
        <li class="toctree-l1 has-children" style="display: flex; justify-content: center; align-items: center; flex-direction: column;">
          <div  style ="text-align:center;">
            <label for="version-select" style="font-weight: bold; display: block;">Version</label>
          </div>
          <select id="version-select" class="version-dropdown" style="margin: 0 auto; display: block;" onchange="location = this.value;">
            <option value="humanoids_imitation.html" selected>develop</option>
            <option value="../../../../main/index.html" >main</option>
            <option value="../../../../release/2.1.0/index.html" >release/2.1.0</option>
            <option value="../../../../release/2.2.0/index.html" >release/2.2.0</option>
            <option value="../../../../release/2.3.0/index.html" >release/2.3.0</option>
            <option value="../../../../v2.3.2/index.html" >v2.3.2</option>
            <option value="../../../../v2.3.1/index.html" >v2.3.1</option>
            <option value="../../../../v2.3.0/index.html" >v2.3.0</option>
            <option value="../../../../v2.2.1/index.html" >v2.2.1</option>
            <option value="../../../../v2.2.0/index.html" >v2.2.0</option>
            <option value="../../../../v2.1.1/index.html" >v2.1.1</option>
            <option value="../../../../v2.1.0/index.html" >v2.1.0</option>
            <option value="../../../../v2.0.2/index.html" >v2.0.2</option>
            <option value="../../../../v2.0.1/index.html" >v2.0.1</option>
            <option value="../../../../v2.0.0/index.html" >v2.0.0</option>
            <option value="../../../../v1.4.1/index.html" >v1.4.1</option>
            <option value="../../../../v1.4.0/index.html" >v1.4.0</option>
            <option value="../../../../v1.3.0/index.html" >v1.3.0</option>
            <option value="../../../../v1.2.0/index.html" >v1.2.0</option>
            <option value="../../../../v1.1.0/index.html" >v1.1.0</option>
            <option value="../../../../v1.0.0/index.html" >v1.0.0</option>
          </select>
        </li>
      </ul>
    </div>
</nav>
</div>
        <div class="sidebar-primary-item"><ul class="navbar-icon-links"
    aria-label="Quick Links">
        <li class="nav-item">
          
          
          
          
          
          
          
          
          <a href="https://github.com/isaac-sim/IsaacLab" title="GitHub" class="nav-link pst-navbar-icon" rel="noopener" target="_blank" data-bs-toggle="tooltip" data-bs-placement="bottom"><i class="fa-brands fa-square-github fa-lg" aria-hidden="true"></i>
            <span class="sr-only">GitHub</span></a>
        </li>
        <li class="nav-item">
          
          
          
          
          
          
          
          
          <a href="https://developer.nvidia.com/isaac-sim" title="Isaac Sim" class="nav-link pst-navbar-icon" rel="noopener" target="_blank" data-bs-toggle="tooltip" data-bs-placement="bottom"><img src="https://img.shields.io/badge/IsaacSim-6.0.0-silver.svg" class="icon-link-image" alt="Isaac Sim"/></a>
        </li>
        <li class="nav-item">
          
          
          
          
          
          
          
          
          <a href="https://img.shields.io/github/stars/isaac-sim/IsaacLab?color=fedcba" title="Stars" class="nav-link pst-navbar-icon" rel="noopener" target="_blank" data-bs-toggle="tooltip" data-bs-placement="bottom"><img src="https://img.shields.io/github/stars/isaac-sim/IsaacLab?color=fedcba" class="icon-link-image" alt="Stars"/></a>
        </li>
</ul></div>
        <div class="sidebar-primary-item">
<form class="bd-search d-flex align-items-center"
      action="../../../search.html"
      method="get">
  <i class="fa-solid fa-magnifying-glass"></i>
  <input type="search"
         class="form-control"
         name="q"
         placeholder="Search..."
         aria-label="Search..."
         autocomplete="off"
         autocorrect="off"
         autocapitalize="off"
         spellcheck="false"/>
  <span class="search-button__kbd-shortcut"><kbd class="kbd-shortcut__modifier">Ctrl</kbd>+<kbd>K</kbd></span>
</form></div>
        <div class="sidebar-primary-item"><nav class="bd-links" id="bd-docs-nav" aria-label="Main">
    <div class="bd-toc-item navbar-nav active">
        <p aria-level="2" class="caption" role="heading"><span class="caption-text">Isaac Lab</span></p>
<ul class="nav bd-sidenav">
<li class="toctree-l1"><a class="reference internal" href="../../setup/ecosystem.html">Isaac Lab Ecosystem</a></li>
<li class="toctree-l1 has-children"><a class="reference internal" href="../../setup/installation/index.html">Local Installation</a><details><summary><span class="toctree-toggle" role="presentation"><i class="fa-solid fa-chevron-down"></i></span></summary><ul>
<li class="toctree-l2"><a class="reference internal" href="../../setup/installation/pip_installation.html">Installation using Isaac Sim Pip Package</a></li>
<li class="toctree-l2"><a class="reference internal" href="../../setup/installation/binaries_installation.html">Installation using Isaac Sim Pre-built Binaries</a></li>
<li class="toctree-l2"><a class="reference internal" href="../../setup/installation/source_installation.html">Installation using Isaac Sim Source Code</a></li>
<li class="toctree-l2"><a class="reference internal" href="../../setup/installation/isaaclab_pip_installation.html">Installation using Isaac Lab Pip Packages</a></li>
<li class="toctree-l2"><a class="reference internal" href="../../setup/installation/asset_caching.html">Asset Caching</a></li>
</ul>
</details></li>
<li class="toctree-l1 has-children"><a class="reference internal" href="../../deployment/index.html">Container Deployment</a><details><summary><span class="toctree-toggle" role="presentation"><i class="fa-solid fa-chevron-down"></i></span></summary><ul>
<li class="toctree-l2"><a class="reference internal" href="../../deployment/docker.html">Docker Guide</a></li>
<li class="toctree-l2"><a class="reference internal" href="../../deployment/run_docker_example.html">Running an example with Docker</a></li>
<li class="toctree-l2"><a class="reference internal" href="../../deployment/cluster.html">Cluster Guide</a></li>
<li class="toctree-l2"><a class="reference internal" href="../../deployment/cloudxr_teleoperation_cluster.html">Deploying CloudXR Teleoperation on Kubernetes</a></li>
</ul>
</details></li>
<li class="toctree-l1"><a class="reference internal" href="../../setup/installation/cloud_installation.html">Cloud Deployment</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../refs/reference_architecture/index.html">Reference Architecture</a></li>
</ul>
<p aria-level="2" class="caption" role="heading"><span class="caption-text">Getting Started</span></p>
<ul class="nav bd-sidenav">
<li class="toctree-l1"><a class="reference internal" href="../../setup/quickstart.html">Quickstart Guide</a></li>
<li class="toctree-l1 has-children"><a class="reference internal" href="../own-project/index.html">Build your Own Project or Task</a><details><summary><span class="toctree-toggle" role="presentation"><i class="fa-solid fa-chevron-down"></i></span></summary><ul>
<li class="toctree-l2"><a class="reference internal" href="../own-project/template.html">Create new project or task</a></li>
<li class="toctree-l2"><a class="reference internal" href="../own-project/project_structure.html">Project Structure</a></li>
</ul>
</details></li>
<li class="toctree-l1 has-children"><a class="reference internal" href="../../setup/walkthrough/index.html">Walkthrough</a><details><summary><span class="toctree-toggle" role="presentation"><i class="fa-solid fa-chevron-down"></i></span></summary><ul>
<li class="toctree-l2"><a class="reference internal" href="../../setup/walkthrough/concepts_env_design.html">Environment Design Background</a></li>
<li class="toctree-l2"><a class="reference internal" href="../../setup/walkthrough/api_env_design.html">Classes and Configs</a></li>
<li class="toctree-l2"><a class="reference internal" href="../../setup/walkthrough/technical_env_design.html">Environment Design</a></li>
<li class="toctree-l2"><a class="reference internal" href="../../setup/walkthrough/training_jetbot_gt.html">Training the Jetbot: Ground Truth</a></li>
<li class="toctree-l2"><a class="reference internal" href="../../setup/walkthrough/training_jetbot_reward_exploration.html">Exploring the RL problem</a></li>
</ul>
</details></li>
<li class="toctree-l1 has-children"><a class="reference internal" href="../../tutorials/index.html">Tutorials</a><details><summary><span class="toctree-toggle" role="presentation"><i class="fa-solid fa-chevron-down"></i></span></summary><ul>
<li class="toctree-l2"><a class="reference internal" href="../../tutorials/00_sim/create_empty.html">Creating an empty scene</a></li>
<li class="toctree-l2"><a class="reference internal" href="../../tutorials/00_sim/spawn_prims.html">Spawning prims into the scene</a></li>
<li class="toctree-l2"><a class="reference internal" href="../../tutorials/00_sim/launch_app.html">Deep-dive into AppLauncher</a></li>
<li class="toctree-l2"><a class="reference internal" href="../../tutorials/01_assets/add_new_robot.html">Adding a New Robot to Isaac Lab</a></li>
<li class="toctree-l2"><a class="reference internal" href="../../tutorials/01_assets/run_rigid_object.html">Interacting with a rigid object</a></li>
<li class="toctree-l2"><a class="reference internal" href="../../tutorials/01_assets/run_articulation.html">Interacting with an articulation</a></li>
<li class="toctree-l2"><a class="reference internal" href="../../tutorials/01_assets/run_deformable_object.html">Interacting with a deformable object</a></li>
<li class="toctree-l2"><a class="reference internal" href="../../tutorials/01_assets/run_surface_gripper.html">Interacting with a surface gripper</a></li>
<li class="toctree-l2"><a class="reference internal" href="../../tutorials/02_scene/create_scene.html">Using the Interactive Scene</a></li>
<li class="toctree-l2"><a class="reference internal" href="../../tutorials/03_envs/create_manager_base_env.html">Creating a Manager-Based Base Environment</a></li>
<li class="toctree-l2"><a class="reference internal" href="../../tutorials/03_envs/create_manager_rl_env.html">Creating a Manager-Based RL Environment</a></li>
<li class="toctree-l2"><a class="reference internal" href="../../tutorials/03_envs/create_direct_rl_env.html">Creating a Direct Workflow RL Environment</a></li>
<li class="toctree-l2"><a class="reference internal" href="../../tutorials/03_envs/register_rl_env_gym.html">Registering an Environment</a></li>
<li class="toctree-l2"><a class="reference internal" href="../../tutorials/03_envs/run_rl_training.html">Training with an RL Agent</a></li>
<li class="toctree-l2"><a class="reference internal" href="../../tutorials/03_envs/configuring_rl_training.html">Configuring an RL Agent</a></li>
<li class="toctree-l2"><a class="reference internal" href="../../tutorials/03_envs/modify_direct_rl_env.html">Modifying an existing Direct RL Environment</a></li>
<li class="toctree-l2"><a class="reference internal" href="../../tutorials/03_envs/policy_inference_in_usd.html">Policy Inference in USD Environment</a></li>
<li class="toctree-l2"><a class="reference internal" href="../../tutorials/04_sensors/add_sensors_on_robot.html">Adding sensors on a robot</a></li>
<li class="toctree-l2"><a class="reference internal" href="../../tutorials/05_controllers/run_diff_ik.html">Using a task-space controller</a></li>
<li class="toctree-l2"><a class="reference internal" href="../../tutorials/05_controllers/run_osc.html">Using an operational space controller</a></li>
</ul>
</details></li>
<li class="toctree-l1 has-children"><a class="reference internal" href="../../how-to/index.html">How-to Guides</a><details><summary><span class="toctree-toggle" role="presentation"><i class="fa-solid fa-chevron-down"></i></span></summary><ul>
<li class="toctree-l2"><a class="reference internal" href="../../how-to/import_new_asset.html">Importing a New Asset</a></li>
<li class="toctree-l2"><a class="reference internal" href="../../how-to/write_articulation_cfg.html">Writing an Asset Configuration</a></li>
<li class="toctree-l2"><a class="reference internal" href="../../how-to/make_fixed_prim.html">Making a physics prim fixed in the simulation</a></li>
<li class="toctree-l2"><a class="reference internal" href="../../how-to/multi_asset_spawning.html">Spawning Multiple Assets</a></li>
<li class="toctree-l2"><a class="reference internal" href="../../how-to/save_camera_output.html">Saving rendered images and 3D re-projection</a></li>
<li class="toctree-l2"><a class="reference internal" href="../../how-to/estimate_how_many_cameras_can_run.html">Find How Many/What Cameras You Should Train With</a></li>
<li class="toctree-l2"><a class="reference internal" href="../../how-to/configure_rendering.html">Configuring Rendering Settings</a></li>
<li class="toctree-l2"><a class="reference internal" href="../../how-to/draw_markers.html">Creating Visualization Markers</a></li>
<li class="toctree-l2"><a class="reference internal" href="../../how-to/wrap_rl_env.html">Wrapping environments</a></li>
<li class="toctree-l2"><a class="reference internal" href="../../how-to/add_own_library.html">Adding your own learning library</a></li>
<li class="toctree-l2"><a class="reference internal" href="../../how-to/record_animation.html">Recording Animations of Simulations</a></li>
<li class="toctree-l2"><a class="reference internal" href="../../how-to/record_video.html">Recording video clips during training</a></li>
<li class="toctree-l2"><a class="reference internal" href="../../how-to/curriculums.html">Curriculum Utilities</a></li>
<li class="toctree-l2"><a class="reference internal" href="../../how-to/master_omniverse.html">Mastering Omniverse for Robotics</a></li>
<li class="toctree-l2"><a class="reference internal" href="../../how-to/cloudxr_teleoperation.html">Setting up CloudXR Teleoperation</a></li>
<li class="toctree-l2"><a class="reference internal" href="../../how-to/haply_teleoperation.html">Setting up Haply Teleoperation</a></li>
<li class="toctree-l2"><a class="reference internal" href="../../how-to/simulation_performance.html">Simulation Performance  and Tuning</a></li>
<li class="toctree-l2"><a class="reference internal" href="../../how-to/optimize_stage_creation.html">Optimize Stage Creation</a></li>
</ul>
</details></li>
<li class="toctree-l1 has-children"><a class="reference internal" href="../developer-guide/index.html">Developer’s Guide</a><details><summary><span class="toctree-toggle" role="presentation"><i class="fa-solid fa-chevron-down"></i></span></summary><ul>
<li class="toctree-l2"><a class="reference internal" href="../developer-guide/vs_code.html">Setting up Visual Studio Code</a></li>


<li class="toctree-l2"><a class="reference internal" href="../developer-guide/repo_structure.html">Repository organization</a></li>
<li class="toctree-l2"><a class="reference internal" href="../developer-guide/development.html">Extension Development</a></li>
</ul>
</details></li>
<li class="toctree-l1 has-children"><a class="reference internal" href="../../testing/index.html">Testing</a><details><summary><span class="toctree-toggle" role="presentation"><i class="fa-solid fa-chevron-down"></i></span></summary><ul>
<li class="toctree-l2"><a class="reference internal" href="../../testing/mock_interfaces.html">Mock Interfaces for Unit Testing</a></li>
<li class="toctree-l2"><a class="reference internal" href="../../testing/micro_benchmarks.html">Micro-Benchmarks for Performance Testing</a></li>
<li class="toctree-l2"><a class="reference internal" href="../../testing/benchmarks.html">Benchmarking Framework</a></li>
</ul>
</details></li>
</ul>
<p aria-level="2" class="caption" role="heading"><span class="caption-text">Overview</span></p>
<ul class="current nav bd-sidenav">
<li class="toctree-l1 has-children"><a class="reference internal" href="../core-concepts/index.html">Core Concepts</a><details><summary><span class="toctree-toggle" role="presentation"><i class="fa-solid fa-chevron-down"></i></span></summary><ul>
<li class="toctree-l2"><a class="reference internal" href="../core-concepts/task_workflows.html">Task Design Workflows</a></li>
<li class="toctree-l2"><a class="reference internal" href="../core-concepts/actuators.html">Actuators</a></li>
<li class="toctree-l2 has-children"><a class="reference internal" href="../core-concepts/sensors/index.html">Sensors</a><details><summary><span class="toctree-toggle" role="presentation"><i class="fa-solid fa-chevron-down"></i></span></summary><ul>
<li class="toctree-l3"><a class="reference internal" href="../core-concepts/sensors/camera.html">Camera</a></li>
<li class="toctree-l3"><a class="reference internal" href="../core-concepts/sensors/contact_sensor.html">Contact Sensor</a></li>
<li class="toctree-l3"><a class="reference internal" href="../core-concepts/sensors/frame_transformer.html">Frame Transformer</a></li>
<li class="toctree-l3"><a class="reference internal" href="../core-concepts/sensors/imu.html">Inertial Measurement Unit (IMU)</a></li>
<li class="toctree-l3"><a class="reference internal" href="../core-concepts/sensors/ray_caster.html">Ray Caster</a></li>
<li class="toctree-l3"><a class="reference internal" href="../core-concepts/sensors/visuo_tactile_sensor.html">Visuo-Tactile Sensor</a></li>
</ul>
</details></li>
<li class="toctree-l2"><a class="reference internal" href="../core-concepts/motion_generators.html">Motion Generators</a></li>
</ul>
</details></li>
<li class="toctree-l1"><a class="reference internal" href="../environments.html">Available Environments</a></li>

<li class="toctree-l1 has-children"><a class="reference internal" href="../reinforcement-learning/index.html">Reinforcement Learning</a><details><summary><span class="toctree-toggle" role="presentation"><i class="fa-solid fa-chevron-down"></i></span></summary><ul>
<li class="toctree-l2"><a class="reference internal" href="../reinforcement-learning/rl_existing_scripts.html">Reinforcement Learning Scripts</a></li>
<li class="toctree-l2"><a class="reference internal" href="../reinforcement-learning/rl_frameworks.html">Reinforcement Learning Library Comparison</a></li>
<li class="toctree-l2"><a class="reference internal" href="../reinforcement-learning/performance_benchmarks.html">Performance Benchmarks</a></li>
<li class="toctree-l2"><a class="reference internal" href="../reinforcement-learning/training_guide.html">Debugging and Training Guide</a></li>
</ul>
</details></li>
<li class="toctree-l1 current active has-children"><a class="reference internal" href="index.html">Imitation Learning</a><details open="open"><summary><span class="toctree-toggle" role="presentation"><i class="fa-solid fa-chevron-down"></i></span></summary><ul class="current">
<li class="toctree-l2"><a class="reference internal" href="teleop_imitation.html">Teleoperation and Imitation Learning with Isaac Lab Mimic</a></li>
<li class="toctree-l2 current active"><a class="current reference internal" href="#">Examples: Data Generation and Imitation Learning for Humanoids</a></li>
<li class="toctree-l2"><a class="reference internal" href="augmented_imitation.html">Augmented Imitation Learning</a></li>
<li class="toctree-l2"><a class="reference internal" href="skillgen.html">SkillGen for Automated Demonstration Generation</a></li>
</ul>
</details></li>
<li class="toctree-l1"><a class="reference internal" href="../showroom.html">Showroom Demos</a></li>
<li class="toctree-l1"><a class="reference internal" href="../simple_agents.html">Simple Agents</a></li>
</ul>
<p aria-level="2" class="caption" role="heading"><span class="caption-text">Features</span></p>
<ul class="nav bd-sidenav">
<li class="toctree-l1"><a class="reference internal" href="../../features/hydra.html">Hydra Configuration System</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../features/multi_gpu.html">Multi-GPU and Multi-Node Training</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../features/population_based_training.html">Population Based Training</a></li>
<li class="toctree-l1"><a class="reference internal" href="../core-concepts/sensors/camera.html">Tiled Rendering</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../features/ray.html">Ray Job Dispatch and Tuning</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../features/reproducibility.html">Reproducibility and Determinism</a></li>
</ul>
<p aria-level="2" class="caption" role="heading"><span class="caption-text">Experimental Features</span></p>
<ul class="nav bd-sidenav">
<li class="toctree-l1"><a class="reference internal" href="../../experimental-features/bleeding-edge.html">Welcome to the bleeding edge!</a></li>
<li class="toctree-l1 has-children"><a class="reference internal" href="../../experimental-features/newton-physics-integration/index.html">Newton Physics Integration</a><details><summary><span class="toctree-toggle" role="presentation"><i class="fa-solid fa-chevron-down"></i></span></summary><ul>
<li class="toctree-l2"><a class="reference internal" href="../../experimental-features/newton-physics-integration/installation.html">Installation</a></li>
<li class="toctree-l2"><a class="reference internal" href="../../experimental-features/newton-physics-integration/isaaclab_newton-beta-2.html">Isaac Lab - Newton Beta 2</a></li>

<li class="toctree-l2"><a class="reference internal" href="../../experimental-features/newton-physics-integration/training-environments.html">Training Environments</a></li>
<li class="toctree-l2"><a class="reference internal" href="../../experimental-features/newton-physics-integration/visualization.html">Visualization</a></li>
<li class="toctree-l2"><a class="reference internal" href="../../experimental-features/newton-physics-integration/limitations-and-known-bugs.html">Limitations</a></li>
<li class="toctree-l2"><a class="reference internal" href="../../experimental-features/newton-physics-integration/solver-transitioning.html">Solver Transitioning</a></li>
<li class="toctree-l2"><a class="reference internal" href="../../experimental-features/newton-physics-integration/sim-to-sim.html">Sim-to-Sim Policy Transfer</a></li>
<li class="toctree-l2"><a class="reference internal" href="../../experimental-features/newton-physics-integration/sim-to-real.html">Sim-to-Real Policy Transfer</a></li>
</ul>
</details></li>
</ul>
<p aria-level="2" class="caption" role="heading"><span class="caption-text">Resources</span></p>
<ul class="nav bd-sidenav">
<li class="toctree-l1"><a class="reference internal" href="../../setup/installation/cloud_installation.html">Cloud Deployment</a></li>
<li class="toctree-l1 has-children"><a class="reference internal" href="../../policy_deployment/index.html">Sim2Real Deployment of Policies Trained in Isaac Lab</a><details><summary><span class="toctree-toggle" role="presentation"><i class="fa-solid fa-chevron-down"></i></span></summary><ul>
<li class="toctree-l2"><a class="reference internal" href="../../policy_deployment/00_hover/hover_policy.html">Training &amp; Deploying HOVER Policy</a></li>
<li class="toctree-l2"><a class="reference internal" href="../../policy_deployment/01_io_descriptors/io_descriptors_101.html">IO Descriptors 101</a></li>
<li class="toctree-l2"><a class="reference internal" href="../../policy_deployment/02_gear_assembly/gear_assembly_policy.html">Training a Gear Insertion Policy and ROS Deployment</a></li>
</ul>
</details></li>
</ul>
<p aria-level="2" class="caption" role="heading"><span class="caption-text">Migration Guides</span></p>
<ul class="nav bd-sidenav">
<li class="toctree-l1"><a class="reference internal" href="../../migration/migrating_to_isaaclab_3-0.html">Migrating to Isaac Lab 3.0</a></li>
<li class="toctree-l1 has-children"><a class="reference internal" href="../../migration/migrating_from_isaacgymenvs.html">From IsaacGymEnvs</a><details><summary><span class="toctree-toggle" role="presentation"><i class="fa-solid fa-chevron-down"></i></span></summary><ul>
<li class="toctree-l2"><a class="reference internal" href="../../migration/comparing_simulation_isaacgym.html">Comparing Simulations Between Isaac Gym and Isaac Lab</a></li>
</ul>
</details></li>
<li class="toctree-l1"><a class="reference internal" href="../../migration/migrating_from_omniisaacgymenvs.html">From OmniIsaacGymEnvs</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../migration/migrating_from_orbit.html">From Orbit</a></li>
</ul>
<p aria-level="2" class="caption" role="heading"><span class="caption-text">Source API</span></p>
<ul class="nav bd-sidenav">
<li class="toctree-l1 has-children"><a class="reference internal" href="../../api/index.html">API Reference</a><details><summary><span class="toctree-toggle" role="presentation"><i class="fa-solid fa-chevron-down"></i></span></summary><ul>
<li class="toctree-l2"><a class="reference internal" href="../../api/lab/isaaclab.app.html">isaaclab.app</a></li>
<li class="toctree-l2"><a class="reference internal" href="../../api/lab/isaaclab.actuators.html">isaaclab.actuators</a></li>
<li class="toctree-l2"><a class="reference internal" href="../../api/lab/isaaclab.assets.html">isaaclab.assets</a></li>
<li class="toctree-l2"><a class="reference internal" href="../../api/lab/isaaclab.controllers.html">isaaclab.controllers</a></li>
<li class="toctree-l2"><a class="reference internal" href="../../api/lab/isaaclab.devices.html">isaaclab.devices</a></li>
<li class="toctree-l2"><a class="reference internal" href="../../api/lab/isaaclab.envs.html">isaaclab.envs</a></li>
<li class="toctree-l2"><a class="reference internal" href="../../api/lab/isaaclab.managers.html">isaaclab.managers</a></li>
<li class="toctree-l2"><a class="reference internal" href="../../api/lab/isaaclab.markers.html">isaaclab.markers</a></li>
<li class="toctree-l2"><a class="reference internal" href="../../api/lab/isaaclab.scene.html">isaaclab.scene</a></li>
<li class="toctree-l2"><a class="reference internal" href="../../api/lab/isaaclab.sensors.html">isaaclab.sensors</a></li>
<li class="toctree-l2"><a class="reference internal" href="../../api/lab/isaaclab.sim.html">isaaclab.sim</a></li>
<li class="toctree-l2"><a class="reference internal" href="../../api/lab/isaaclab.terrains.html">isaaclab.terrains</a></li>
<li class="toctree-l2"><a class="reference internal" href="../../api/lab/isaaclab.utils.html">isaaclab.utils</a></li>
<li class="toctree-l2"><a class="reference internal" href="../../api/lab/isaaclab.envs.mdp.html">isaaclab.envs.mdp</a></li>
<li class="toctree-l2"><a class="reference internal" href="../../api/lab/isaaclab.envs.ui.html">isaaclab.envs.ui</a></li>
<li class="toctree-l2"><a class="reference internal" href="../../api/lab/isaaclab.sensors.patterns.html">isaaclab.sensors.patterns</a></li>
<li class="toctree-l2"><a class="reference internal" href="../../api/lab/isaaclab.sim.converters.html">isaaclab.sim.converters</a></li>
<li class="toctree-l2"><a class="reference internal" href="../../api/lab/isaaclab.sim.schemas.html">isaaclab.sim.schemas</a></li>
<li class="toctree-l2"><a class="reference internal" href="../../api/lab/isaaclab.sim.spawners.html">isaaclab.sim.spawners</a></li>
<li class="toctree-l2"><a class="reference internal" href="../../api/lab/isaaclab.sim.views.html">isaaclab.sim.views</a></li>
<li class="toctree-l2"><a class="reference internal" href="../../api/lab/isaaclab.sim.utils.html">isaaclab.sim.utils</a></li>
<li class="toctree-l2"><a class="reference internal" href="../../api/lab_rl/isaaclab_rl.html">isaaclab_rl</a></li>
<li class="toctree-l2"><a class="reference internal" href="../../api/lab_mimic/isaaclab_mimic.datagen.html">isaaclab_mimic.datagen</a></li>
<li class="toctree-l2"><a class="reference internal" href="../../api/lab_mimic/isaaclab_mimic.envs.html">isaaclab_mimic.envs</a></li>
<li class="toctree-l2"><a class="reference internal" href="../../api/lab_contrib/isaaclab_contrib.actuators.html">isaaclab_contrib.actuators</a></li>
<li class="toctree-l2"><a class="reference internal" href="../../api/lab_contrib/isaaclab_contrib.assets.html">isaaclab_contrib.assets</a></li>
<li class="toctree-l2"><a class="reference internal" href="../../api/lab_contrib/isaaclab_contrib.mdp.html">isaaclab_contrib.mdp</a></li>
<li class="toctree-l2"><a class="reference internal" href="../../api/lab_contrib/isaaclab_contrib.rl.html">isaaclab_contrib.rl</a></li>
<li class="toctree-l2"><a class="reference internal" href="../../api/lab_contrib/isaaclab_contrib.sensors.html">isaaclab_contrib.sensors</a></li>
<li class="toctree-l2"><a class="reference internal" href="../../api/lab_tasks/isaaclab_tasks.utils.html">isaaclab_tasks.utils</a></li>
<li class="toctree-l2"><a class="reference internal" href="../../api/lab_teleop/isaaclab_teleop.html">isaaclab_teleop</a></li>
<li class="toctree-l2"><a class="reference internal" href="../../api/lab_physx/isaaclab_physx.assets.html">isaaclab_physx.assets</a></li>
<li class="toctree-l2"><a class="reference internal" href="../../api/lab_physx/isaaclab_physx.assets.html">isaaclab_physx.assets</a></li>
</ul>
</details></li>
</ul>
<p aria-level="2" class="caption" role="heading"><span class="caption-text">References</span></p>
<ul class="nav bd-sidenav">
<li class="toctree-l1"><a class="reference internal" href="../../refs/additional_resources.html">Additional Resources</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../refs/contributing.html">Contribution Guidelines</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../refs/troubleshooting.html">Tricks and Troubleshooting</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../refs/migration.html">Migration Guide (Isaac Sim)</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../refs/issues.html">Known Issues</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../refs/release_notes.html">Release Notes</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../refs/changelog.html">Extensions Changelog</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../refs/license.html">License</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../refs/bibliography.html">Bibliography</a></li>
</ul>
<p aria-level="2" class="caption" role="heading"><span class="caption-text">Project Links</span></p>
<ul class="nav bd-sidenav">
<li class="toctree-l1"><a class="reference external" href="https://github.com/isaac-sim/IsaacLab">GitHub</a></li>
<li class="toctree-l1"><a class="reference external" href="https://docs.isaacsim.omniverse.nvidia.com/latest/index.html">NVIDIA Isaac Sim</a></li>
<li class="toctree-l1"><a class="reference external" href="https://nvidia-omniverse.github.io/PhysX/physx/5.4.1/index.html">NVIDIA PhysX</a></li>
</ul>

    </div>
</nav></div>
    </div>
  
  
  <div class="sidebar-primary-items__end sidebar-primary__section">
      <div class="sidebar-primary-item">
<div id="ethical-ad-placement"
      class="flat"
      data-ea-publisher="readthedocs"
      data-ea-type="readthedocs-sidebar"
      data-ea-manual="true">
</div></div>
  </div>


      </div>
      
      <main id="main-content" class="bd-main" role="main">
        
        

<div class="sbt-scroll-pixel-helper"></div>

          <div class="bd-content">
            <div class="bd-article-container">
              
              <div class="bd-header-article d-print-none">
<div class="header-article-items header-article__inner">
  
    <div class="header-article-items__start">
      
        <div class="header-article-item"><label class="sidebar-toggle primary-toggle btn btn-sm" for="__primary" title="Toggle primary sidebar" data-bs-placement="bottom" data-bs-toggle="tooltip">
  <span class="fa-solid fa-bars"></span>
</label></div>
      
    </div>
  
  
    <div class="header-article-items__end">
      
        <div class="header-article-item">

<div class="article-header-buttons">





<div class="dropdown dropdown-source-buttons">
  <button class="btn dropdown-toggle" type="button" data-bs-toggle="dropdown" aria-expanded="false" aria-label="Source repositories">
    <i class="fab fa-github"></i>
  </button>
  <ul class="dropdown-menu">
      
      
      
      <li><a href="https://github.com/isaac-sim/IsaacLab" target="_blank"
   class="btn btn-sm btn-source-repository-button dropdown-item"
   title="Source repository"
   data-bs-placement="left" data-bs-toggle="tooltip"
>
  

<span class="btn__icon-container">
  <i class="fab fa-github"></i>
  </span>
<span class="btn__text-container">Repository</span>
</a>
</li>
      
      
      
      
      <li><a href="https://github.com/isaac-sim/IsaacLab/edit/main/docs/source/overview/imitation-learning/humanoids_imitation.rst" target="_blank"
   class="btn btn-sm btn-source-edit-button dropdown-item"
   title="Suggest edit"
   data-bs-placement="left" data-bs-toggle="tooltip"
>
  

<span class="btn__icon-container">
  <i class="fas fa-pencil-alt"></i>
  </span>
<span class="btn__text-container">Suggest edit</span>
</a>
</li>
      
      
      
      
      <li><a href="https://github.com/isaac-sim/IsaacLab/issues/new?title=Issue%20on%20page%20%2Fsource/overview/imitation-learning/humanoids_imitation.html&body=Your%20issue%20content%20here." target="_blank"
   class="btn btn-sm btn-source-issues-button dropdown-item"
   title="Open an issue"
   data-bs-placement="left" data-bs-toggle="tooltip"
>
  

<span class="btn__icon-container">
  <i class="fas fa-lightbulb"></i>
  </span>
<span class="btn__text-container">Open issue</span>
</a>
</li>
      
  </ul>
</div>






<div class="dropdown dropdown-download-buttons">
  <button class="btn dropdown-toggle" type="button" data-bs-toggle="dropdown" aria-expanded="false" aria-label="Download this page">
    <i class="fas fa-download"></i>
  </button>
  <ul class="dropdown-menu">
      
      
      
      <li><a href="../../../_sources/source/overview/imitation-learning/humanoids_imitation.rst" target="_blank"
   class="btn btn-sm btn-download-source-button dropdown-item"
   title="Download source file"
   data-bs-placement="left" data-bs-toggle="tooltip"
>
  

<span class="btn__icon-container">
  <i class="fas fa-file"></i>
  </span>
<span class="btn__text-container">.rst</span>
</a>
</li>
      
      
      
      
      <li>
<button onclick="window.print()"
  class="btn btn-sm btn-download-pdf-button dropdown-item"
  title="Print to PDF"
  data-bs-placement="left" data-bs-toggle="tooltip"
>
  

<span class="btn__icon-container">
  <i class="fas fa-file-pdf"></i>
  </span>
<span class="btn__text-container">.pdf</span>
</button>
</li>
      
  </ul>
</div>




<button onclick="toggleFullScreen()"
  class="btn btn-sm btn-fullscreen-button"
  title="Fullscreen mode"
  data-bs-placement="bottom" data-bs-toggle="tooltip"
>
  

<span class="btn__icon-container">
  <i class="fas fa-expand"></i>
  </span>

</button>



<button class="btn btn-sm nav-link pst-navbar-icon theme-switch-button pst-js-only" aria-label="Color mode" data-bs-title="Color mode"  data-bs-placement="bottom" data-bs-toggle="tooltip">
  <i class="theme-switch fa-solid fa-sun                fa-lg" data-mode="light" title="Light"></i>
  <i class="theme-switch fa-solid fa-moon               fa-lg" data-mode="dark"  title="Dark"></i>
  <i class="theme-switch fa-solid fa-circle-half-stroke fa-lg" data-mode="auto"  title="System Settings"></i>
</button>


<button class="btn btn-sm pst-navbar-icon search-button search-button__button pst-js-only" title="Search" aria-label="Search" data-bs-placement="bottom" data-bs-toggle="tooltip">
    <i class="fa-solid fa-magnifying-glass fa-lg"></i>
</button>
<label class="sidebar-toggle secondary-toggle btn btn-sm" for="__secondary"title="Toggle secondary sidebar" data-bs-placement="bottom" data-bs-toggle="tooltip">
    <span class="fa-solid fa-list"></span>
</label>
</div></div>
      
    </div>
  
</div>
</div>
              
              

<div id="jb-print-docs-body" class="onlyprint">
    <h1>Examples: Data Generation and Imitation Learning for Humanoids</h1>
    <!-- Table of contents -->
    <div id="print-main-content">
        <div id="jb-print-toc">
            
            <div>
                <h2> Contents </h2>
            </div>
            <nav aria-label="Page">
                <ul class="visible nav section-nav flex-column">
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#demo-1-data-generation-and-policy-training-for-a-humanoid-robot">Demo 1: Data Generation and Policy Training for a Humanoid Robot</a><ul class="nav section-nav flex-column">
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#optional-collect-and-annotate-demonstrations">Optional: Collect and annotate demonstrations</a><ul class="nav section-nav flex-column">
<li class="toc-h4 nav-item toc-entry"><a class="reference internal nav-link" href="#collect-human-demonstrations">Collect human demonstrations</a></li>
<li class="toc-h4 nav-item toc-entry"><a class="reference internal nav-link" href="#annotate-the-demonstrations">Annotate the demonstrations</a></li>
</ul>
</li>
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#generate-the-dataset">Generate the dataset</a></li>
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#train-a-policy">Train a policy</a></li>
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#visualize-the-results">Visualize the results</a></li>
</ul>
</li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#demo-2-visuomotor-policy-for-a-humanoid-robot">Demo 2: Visuomotor Policy for a Humanoid Robot</a><ul class="nav section-nav flex-column">
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#download-the-dataset">Download the Dataset</a></li>
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#id2">Train a policy</a></li>
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#visualize-results-demo-2">Visualize the results</a></li>
</ul>
</li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#demo-3-data-generation-and-policy-training-for-humanoid-robot-locomanipulation-with-unitree-g1">Demo 3: Data Generation and Policy Training for Humanoid Robot Locomanipulation with Unitree G1</a><ul class="nav section-nav flex-column">
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#generate-the-manipulation-dataset">Generate the manipulation dataset</a></li>
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#train-a-manipulation-only-policy">Train a manipulation-only policy</a></li>
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#id4">Visualize the results</a></li>
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#generate-the-dataset-with-manipulation-and-point-to-point-navigation">Generate the dataset with manipulation and point-to-point navigation</a></li>
</ul>
</li>
</ul>
            </nav>
        </div>
    </div>
</div>

              
                
<div id="searchbox"></div>
                <article class="bd-article">
                  
  <section id="examples-data-generation-and-imitation-learning-for-humanoids">
<span id="data-generation-imitation-learning-humanoids"></span><h1>Examples: Data Generation and Imitation Learning for Humanoids<a class="headerlink" href="#examples-data-generation-and-imitation-learning-for-humanoids" title="Permalink to this heading">#</a></h1>
<p>This page covers data generation and imitation learning workflows for humanoid robots (GR-1, G1) with Isaac Lab Mimic:</p>
<ul class="simple">
<li><p><strong>Demo 1:</strong> Data generation and policy training for a humanoid robot (GR-1 pick and place)</p></li>
<li><p><strong>Demo 2:</strong> Visuomotor policy for a humanoid robot (GR-1 nut pouring)</p></li>
<li><p><strong>Demo 3:</strong> Data generation and policy training for humanoid robot locomanipulation (Unitree G1)</p></li>
</ul>
<div class="admonition important">
<p class="admonition-title">Important</p>
<p>Complete the tutorial in <a class="reference internal" href="teleop_imitation.html#teleoperation-imitation-learning"><span class="std std-ref">Teleoperation and Imitation Learning with Isaac Lab Mimic</span></a>
before proceeding with the following demonstrations to
understand the data collection, annotation, and generation steps of Isaac Lab Mimic.</p>
</div>
<section id="demo-1-data-generation-and-policy-training-for-a-humanoid-robot">
<h2>Demo 1: Data Generation and Policy Training for a Humanoid Robot<a class="headerlink" href="#demo-1-data-generation-and-policy-training-for-a-humanoid-robot" title="Permalink to this heading">#</a></h2>
<figure class="align-center">
<a class="reference internal image-reference" href="https://download.isaacsim.omniverse.nvidia.com/isaaclab/images/gr-1_steering_wheel_pick_place.gif"><img alt="GR-1 humanoid robot performing a pick and place task" src="https://download.isaacsim.omniverse.nvidia.com/isaaclab/images/gr-1_steering_wheel_pick_place.gif" style="width: 100%;" /></a>
</figure>
<p>Isaac Lab Mimic supports data generation for robots with multiple end effectors. In the following demonstration, we will show how to generate data
to train a Fourier GR-1 humanoid robot to perform a pick and place task.</p>
<section id="optional-collect-and-annotate-demonstrations">
<h3>Optional: Collect and annotate demonstrations<a class="headerlink" href="#optional-collect-and-annotate-demonstrations" title="Permalink to this heading">#</a></h3>
<section id="collect-human-demonstrations">
<h4>Collect human demonstrations<a class="headerlink" href="#collect-human-demonstrations" title="Permalink to this heading">#</a></h4>
<div class="admonition note">
<p class="admonition-title">Note</p>
<p>Data collection for the GR-1 humanoid robot environment requires use of an Apple Vision Pro headset. If you do not have access to
an Apple Vision Pro, you may skip this step and continue on to the next step: <a class="reference internal" href="#generate-the-dataset"><span class="std std-ref">Generate the dataset</span></a>.
A pre-recorded annotated dataset is provided in the next step.</p>
</div>
<div class="admonition tip">
<p class="admonition-title">Tip</p>
<p>The GR1 scene utilizes the wrist poses from the Apple Vision Pro (AVP) as setpoints for a differential IK controller (Pink-IK).
The differential IK controller requires the user’s wrist pose to be close to the robot’s initial or current pose for optimal performance.
Rapid movements of the user’s wrist may cause it to deviate significantly from the goal state, which could prevent the IK controller from finding the optimal solution.
This may result in a mismatch between the user’s wrist and the robot’s wrist.
You can increase the gain of all the <a class="reference external" href="https://github.com/isaac-sim/IsaacLab/blob/main/source/isaaclab_tasks/isaaclab_tasks/manager_based/manipulation/pick_place/pickplace_gr1t2_env_cfg.py">Pink-IK controller’s FrameTasks</a> to track the AVP wrist poses with lower latency.
However, this may lead to more jerky motion.
Separately, the finger joints of the robot are retargeted to the user’s finger joints using the <a class="reference external" href="https://github.com/dexsuite/dex-retargeting">dex-retargeting</a> library.</p>
</div>
<p>Set up the CloudXR Runtime and Apple Vision Pro for teleoperation by following the steps in <a class="reference internal" href="../../how-to/cloudxr_teleoperation.html#cloudxr-teleoperation"><span class="std std-ref">Setting up CloudXR Teleoperation</span></a>.
CPU simulation is used in the following steps for better XR performance when running a single environment.</p>
<p>Collect a set of human demonstrations.
A success demo requires the object to be placed in the bin and for the robot’s right arm to be retracted to the starting position.</p>
<p>The Isaac Lab Mimic Env GR-1 humanoid robot is set up such that the left hand has a single subtask, while the right hand has two subtasks.
The first subtask involves the right hand remaining idle while the left hand picks up and moves the object to the position where the right hand will grasp it.
This setup allows Isaac Lab Mimic to interpolate the right hand’s trajectory accurately by using the object’s pose, especially when poses are randomized during data generation.
Therefore, avoid moving the right hand while the left hand picks up the object and brings it to a stable position.</p>
<p><a class="reference internal" href="https://download.isaacsim.omniverse.nvidia.com/isaaclab/images/gr-1_steering_wheel_pick_place_good_demo.gif"><img alt="GR-1 humanoid robot performing a good pick and place demonstration" src="https://download.isaacsim.omniverse.nvidia.com/isaaclab/images/gr-1_steering_wheel_pick_place_good_demo.gif" style="width: 49%;" /></a> <a class="reference internal" href="https://download.isaacsim.omniverse.nvidia.com/isaaclab/images/gr-1_steering_wheel_pick_place_bad_demo.gif"><img alt="GR-1 humanoid robot performing a bad pick and place demonstration" src="https://download.isaacsim.omniverse.nvidia.com/isaaclab/images/gr-1_steering_wheel_pick_place_bad_demo.gif" style="width: 49%;" /></a></p>
<p class="centered">
<strong>Left: A good human demonstration with smooth and steady motion. Right: A bad demonstration with jerky and exaggerated motion.</strong></p><p>Collect five demonstrations by running the following command:</p>
<div class="highlight-bash notranslate"><div class="highlight"><pre><span></span>./isaaclab.sh<span class="w"> </span>-p<span class="w"> </span>scripts/tools/record_demos.py<span class="w"> </span><span class="se">\</span>
--task<span class="w"> </span>Isaac-PickPlace-GR1T2-Abs-v0<span class="w"> </span><span class="se">\</span>
--visualizer<span class="w"> </span>kit<span class="w"> </span><span class="se">\</span>
--device<span class="w"> </span>cpu<span class="w"> </span><span class="se">\</span>
--teleop_device<span class="w"> </span>handtracking<span class="w"> </span><span class="se">\</span>
--num_demos<span class="w"> </span><span class="m">5</span><span class="w"> </span><span class="se">\</span>
--dataset_file<span class="w"> </span>./datasets/dataset_gr1.hdf5
</pre></div>
</div>
<div class="admonition note">
<p class="admonition-title">Note</p>
<p>We also provide a GR-1 pick and place task with waist degrees-of-freedom enabled <code class="docutils literal notranslate"><span class="pre">Isaac-PickPlace-GR1T2-WaistEnabled-Abs-v0</span></code> (see <a class="reference internal" href="../environments.html#environments"><span class="std std-ref">Available Environments</span></a> for details on the available environments, including the GR1 Waist Enabled variant). The same command above applies but with the task name changed to <code class="docutils literal notranslate"><span class="pre">Isaac-PickPlace-GR1T2-WaistEnabled-Abs-v0</span></code>.</p>
</div>
<div class="admonition tip">
<p class="admonition-title">Tip</p>
<p>If a demo fails during data collection, the environment can be reset using the teleoperation controls panel in the XR teleop client
on the Apple Vision Pro or via voice control by saying “reset”. See <a class="reference internal" href="../../how-to/cloudxr_teleoperation.html#teleoperate-apple-vision-pro"><span class="std std-ref">Teleoperate an Isaac Lab Robot with Apple Vision Pro</span></a> for more details.</p>
<p>The robot uses simplified collision meshes for physics calculations that differ from the detailed visual meshes displayed in the simulation. Due to this difference, you may occasionally observe visual artifacts where parts of the robot appear to penetrate other objects or itself, even though proper collision handling is occurring in the physics simulation.</p>
</div>
<p>You can replay the collected demonstrations by running the following command:</p>
<div class="highlight-bash notranslate"><div class="highlight"><pre><span></span>./isaaclab.sh<span class="w"> </span>-p<span class="w"> </span>scripts/tools/replay_demos.py<span class="w"> </span><span class="se">\</span>
--task<span class="w"> </span>Isaac-PickPlace-GR1T2-Abs-v0<span class="w"> </span><span class="se">\</span>
--visualizer<span class="w"> </span>kit<span class="w"> </span><span class="se">\</span>
--device<span class="w"> </span>cpu<span class="w"> </span><span class="se">\</span>
--dataset_file<span class="w"> </span>./datasets/dataset_gr1.hdf5
</pre></div>
</div>
<div class="admonition note">
<p class="admonition-title">Note</p>
<p>Non-determinism may be observed during replay as physics in IsaacLab are not determimnistically reproducible when using <code class="docutils literal notranslate"><span class="pre">env.reset</span></code>.</p>
</div>
</section>
<section id="annotate-the-demonstrations">
<h4>Annotate the demonstrations<a class="headerlink" href="#annotate-the-demonstrations" title="Permalink to this heading">#</a></h4>
<p>Unlike the <a class="reference internal" href="teleop_imitation.html#generating-additional-demonstrations"><span class="std std-ref">Franka stacking task</span></a>, the GR-1 pick and place task uses manual annotation to define subtasks.</p>
<p>The pick and place task has one subtask for the left arm (pick) and two subtasks for the right arm (idle, place).
Annotations denote the end of a subtask. For the pick and place task, this means there are no annotations for the left arm and one annotation for the right arm (the end of the final subtask is always implicit).</p>
<p>Each demo requires a single annotation between the first and second subtask of the right arm. This annotation (“S” button press) should be done when the right robot arm finishes the “idle” subtask and begins to
move towards the target object. An example of a correct annotation is shown below:</p>
<figure class="align-center">
<a class="reference internal image-reference" href="../../../_images/gr-1_pick_place_annotation.jpg"><img alt="../../../_images/gr-1_pick_place_annotation.jpg" src="../../../_images/gr-1_pick_place_annotation.jpg" style="width: 100%;" /></a>
</figure>
<p>Annotate the demonstrations by running the following command:</p>
<div class="highlight-bash notranslate"><div class="highlight"><pre><span></span>./isaaclab.sh<span class="w"> </span>-p<span class="w"> </span>scripts/imitation_learning/isaaclab_mimic/annotate_demos.py<span class="w"> </span><span class="se">\</span>
--task<span class="w"> </span>Isaac-PickPlace-GR1T2-Abs-Mimic-v0<span class="w"> </span><span class="se">\</span>
--visualizer<span class="w"> </span>kit<span class="w"> </span><span class="se">\</span>
--device<span class="w"> </span>cpu<span class="w"> </span><span class="se">\</span>
--input_file<span class="w"> </span>./datasets/dataset_gr1.hdf5<span class="w"> </span><span class="se">\</span>
--output_file<span class="w"> </span>./datasets/dataset_annotated_gr1.hdf5
</pre></div>
</div>
<div class="admonition note">
<p class="admonition-title">Note</p>
<p>The script prints the keyboard commands for manual annotation and the current subtask being annotated:</p>
<div class="highlight-text notranslate"><div class="highlight"><pre><span></span>Annotating episode #0 (demo_0)
   Playing the episode for subtask annotations for eef &quot;right&quot;.
   Subtask signals to annotate:
      - Termination:      [&#39;idle_right&#39;]

   Press &quot;N&quot; to begin.
   Press &quot;B&quot; to pause.
   Press &quot;S&quot; to annotate subtask signals.
   Press &quot;Q&quot; to skip the episode.
</pre></div>
</div>
</div>
<div class="admonition tip">
<p class="admonition-title">Tip</p>
<p>If the object does not get placed in the bin during annotation, you can press “N” to replay the episode and annotate again. Or you can press “Q” to skip the episode and annotate the next one.</p>
</div>
</section>
</section>
<section id="generate-the-dataset">
<span id="id1"></span><h3>Generate the dataset<a class="headerlink" href="#generate-the-dataset" title="Permalink to this heading">#</a></h3>
<p>If you skipped the prior collection and annotation step, download the pre-recorded annotated dataset <code class="docutils literal notranslate"><span class="pre">dataset_annotated_gr1.hdf5</span></code> from
here: <a class="reference external" href="https://omniverse-content-staging.s3-us-west-2.amazonaws.com/Assets/Isaac/6.0/Isaac/IsaacLab/Mimic/pick_place_datasets/dataset_annotated_gr1.hdf5">[Annotated GR1 Dataset]</a>.
Place the file under <code class="docutils literal notranslate"><span class="pre">IsaacLab/datasets</span></code> and run the following command to generate a new dataset with 1000 demonstrations.</p>
<div class="highlight-bash notranslate"><div class="highlight"><pre><span></span>./isaaclab.sh<span class="w"> </span>-p<span class="w"> </span>scripts/imitation_learning/isaaclab_mimic/generate_dataset.py<span class="w"> </span><span class="se">\</span>
--device<span class="w"> </span>cpu<span class="w"> </span><span class="se">\</span>
--headless<span class="w"> </span><span class="se">\</span>
--num_envs<span class="w"> </span><span class="m">20</span><span class="w"> </span><span class="se">\</span>
--generation_num_trials<span class="w"> </span><span class="m">1000</span><span class="w"> </span><span class="se">\</span>
--input_file<span class="w"> </span>./datasets/dataset_annotated_gr1.hdf5<span class="w"> </span><span class="se">\</span>
--output_file<span class="w"> </span>./datasets/generated_dataset_gr1.hdf5
</pre></div>
</div>
</section>
<section id="train-a-policy">
<h3>Train a policy<a class="headerlink" href="#train-a-policy" title="Permalink to this heading">#</a></h3>
<p>Use <a class="reference external" href="https://robomimic.github.io/">Robomimic</a> to train a policy for the generated dataset.</p>
<div class="highlight-bash notranslate"><div class="highlight"><pre><span></span>./isaaclab.sh<span class="w"> </span>-p<span class="w"> </span>scripts/imitation_learning/robomimic/train.py<span class="w"> </span><span class="se">\</span>
--task<span class="w"> </span>Isaac-PickPlace-GR1T2-Abs-v0<span class="w"> </span><span class="se">\</span>
--algo<span class="w"> </span>bc<span class="w"> </span><span class="se">\</span>
--normalize_training_actions<span class="w"> </span><span class="se">\</span>
--dataset<span class="w"> </span>./datasets/generated_dataset_gr1.hdf5
</pre></div>
</div>
<p>The training script will normalize the actions in the dataset to the range [-1, 1].
The normalization parameters are saved in the model directory under <code class="docutils literal notranslate"><span class="pre">PATH_TO_MODEL_DIRECTORY/logs/normalization_params.txt</span></code>.
Record the normalization parameters for later use in the visualization step.</p>
<div class="admonition note">
<p class="admonition-title">Note</p>
<p>By default the trained models and logs will be saved to <code class="docutils literal notranslate"><span class="pre">IssacLab/logs/robomimic</span></code>.</p>
</div>
</section>
<section id="visualize-the-results">
<h3>Visualize the results<a class="headerlink" href="#visualize-the-results" title="Permalink to this heading">#</a></h3>
<p>Visualize the results of the trained policy by running the following command, using the normalization parameters recorded in the prior training step:</p>
<div class="highlight-bash notranslate"><div class="highlight"><pre><span></span>./isaaclab.sh<span class="w"> </span>-p<span class="w"> </span>scripts/imitation_learning/robomimic/play.py<span class="w"> </span><span class="se">\</span>
--task<span class="w"> </span>Isaac-PickPlace-GR1T2-Abs-v0<span class="w"> </span><span class="se">\</span>
--visualizer<span class="w"> </span>kit<span class="w"> </span><span class="se">\</span>
--device<span class="w"> </span>cpu<span class="w"> </span><span class="se">\</span>
--num_rollouts<span class="w"> </span><span class="m">50</span><span class="w"> </span><span class="se">\</span>
--horizon<span class="w"> </span><span class="m">400</span><span class="w"> </span><span class="se">\</span>
--norm_factor_min<span class="w"> </span>&lt;NORM_FACTOR_MIN&gt;<span class="w"> </span><span class="se">\</span>
--norm_factor_max<span class="w"> </span>&lt;NORM_FACTOR_MAX&gt;<span class="w"> </span><span class="se">\</span>
--checkpoint<span class="w"> </span>/PATH/TO/desired_model_checkpoint.pth
</pre></div>
</div>
<div class="admonition note">
<p class="admonition-title">Note</p>
<p>Change the <code class="docutils literal notranslate"><span class="pre">NORM_FACTOR</span></code> in the above command with the values generated in the training step.</p>
</div>
<div class="admonition tip">
<p class="admonition-title">Tip</p>
<p><strong>If you don’t see expected performance results:</strong> It is critical to test policies from various checkpoint epochs.
Performance can vary significantly between epochs, and the best-performing checkpoint is often not the final one.</p>
</div>
<figure class="align-center" id="id5">
<a class="reference internal image-reference" href="https://download.isaacsim.omniverse.nvidia.com/isaaclab/images/gr-1_steering_wheel_pick_place_policy.gif"><img alt="GR-1 humanoid robot performing a pick and place task" src="https://download.isaacsim.omniverse.nvidia.com/isaaclab/images/gr-1_steering_wheel_pick_place_policy.gif" style="width: 100%;" /></a>
<figcaption>
<p><span class="caption-text">The trained policy performing the pick and place task in Isaac Lab.</span><a class="headerlink" href="#id5" title="Permalink to this image">#</a></p>
</figcaption>
</figure>
<div class="admonition note">
<p class="admonition-title">Note</p>
<p><strong>Expected Success Rates and Timings for Pick and Place GR1T2 Task</strong></p>
<ul class="simple">
<li><p>Success rate for data generation depends on the quality of human demonstrations (how well the user performs them) and dataset annotation quality. Both data generation and downstream policy success are sensitive to these factors and can show high variance. See <a class="reference internal" href="teleop_imitation.html#common-pitfalls-generating-data"><span class="std std-ref">Common Pitfalls when Generating Data</span></a> for tips to improve your dataset.</p></li>
<li><p>Data generation success for this task is typically 65-80% over 1000 demonstrations, taking 18-40 minutes depending on GPU hardware and success rate (19 minutes on a RTX ADA 6000 &#64; 80% success rate).</p></li>
<li><p>Behavior Cloning (BC) policy success is typically 75-86% (evaluated on 50 rollouts) when trained on 1000 generated demonstrations for 2000 epochs (default), depending on demonstration quality. Training takes approximately 29 minutes on a RTX ADA 6000.</p></li>
<li><p><strong>Recommendation:</strong> Train for 2000 epochs with 1000 generated demonstrations, and <strong>evaluate multiple checkpoints saved between the 1000th and 2000th epochs</strong> to select the best-performing policy. Testing various epochs is essential for finding optimal performance.</p></li>
</ul>
</div>
</section>
</section>
<section id="demo-2-visuomotor-policy-for-a-humanoid-robot">
<h2>Demo 2: Visuomotor Policy for a Humanoid Robot<a class="headerlink" href="#demo-2-visuomotor-policy-for-a-humanoid-robot" title="Permalink to this heading">#</a></h2>
<figure class="align-center">
<a class="reference internal image-reference" href="https://download.isaacsim.omniverse.nvidia.com/isaaclab/images/gr-1_nut_pouring_policy.gif"><img alt="GR-1 humanoid robot performing a pouring task" src="https://download.isaacsim.omniverse.nvidia.com/isaaclab/images/gr-1_nut_pouring_policy.gif" style="width: 100%;" /></a>
</figure>
<section id="download-the-dataset">
<h3>Download the Dataset<a class="headerlink" href="#download-the-dataset" title="Permalink to this heading">#</a></h3>
<p>Download the pre-generated dataset from <a class="reference external" href="https://omniverse-content-staging.s3-us-west-2.amazonaws.com/Assets/Isaac/6.0/Isaac/IsaacLab/Mimic/pick_place_datasets/generated_dataset_gr1_nut_pouring.hdf5">here</a> and place it under <code class="docutils literal notranslate"><span class="pre">IsaacLab/datasets/generated_dataset_gr1_nut_pouring.hdf5</span></code>
(<strong>Note: The dataset size is approximately 15GB</strong>). The dataset contains 1000 demonstrations of a humanoid robot performing a pouring/placing task that was
generated using Isaac Lab Mimic for the <code class="docutils literal notranslate"><span class="pre">Isaac-NutPour-GR1T2-Pink-IK-Abs-Mimic-v0</span></code> task.</p>
<div class="admonition hint">
<p class="admonition-title">Hint</p>
<p>If desired, data collection, annotation, and generation can be done using the same commands as the prior examples.</p>
<p>The robot first picks up the red beaker and pours the contents into the yellow bowl.
Then, it drops the red beaker into the blue bin. Lastly, it places the yellow bowl onto the white scale.
See the video in the <a class="reference internal" href="#visualize-results-demo-2"><span class="std std-ref">Visualize the results</span></a> section below for a visual demonstration of the task.</p>
<p><strong>The success criteria for this task requires the red beaker to be placed in the blue bin, the green nut to be in the yellow bowl,
and the yellow bowl to be placed on top of the white scale.</strong></p>
<div class="admonition attention">
<p class="admonition-title">Attention</p>
<p><strong>The following commands are only for your reference and are not required for this demo.</strong></p>
</div>
<p>To collect demonstrations:</p>
<div class="highlight-bash notranslate"><div class="highlight"><pre><span></span>./isaaclab.sh<span class="w"> </span>-p<span class="w"> </span>scripts/tools/record_demos.py<span class="w"> </span><span class="se">\</span>
--task<span class="w"> </span>Isaac-NutPour-GR1T2-Pink-IK-Abs-v0<span class="w"> </span><span class="se">\</span>
--visualizer<span class="w"> </span>kit<span class="w"> </span><span class="se">\</span>
--device<span class="w"> </span>cpu<span class="w"> </span><span class="se">\</span>
--teleop_device<span class="w"> </span>handtracking<span class="w"> </span><span class="se">\</span>
--num_demos<span class="w"> </span><span class="m">5</span><span class="w"> </span><span class="se">\</span>
--dataset_file<span class="w"> </span>./datasets/dataset_gr1_nut_pouring.hdf5
</pre></div>
</div>
<p>To annotate the demonstrations:</p>
<div class="highlight-bash notranslate"><div class="highlight"><pre><span></span>./isaaclab.sh<span class="w"> </span>-p<span class="w"> </span>scripts/imitation_learning/isaaclab_mimic/annotate_demos.py<span class="w"> </span><span class="se">\</span>
--task<span class="w"> </span>Isaac-NutPour-GR1T2-Pink-IK-Abs-Mimic-v0<span class="w"> </span><span class="se">\</span>
--visualizer<span class="w"> </span>kit<span class="w"> </span><span class="se">\</span>
--enable_cameras<span class="w"> </span><span class="se">\</span>
--device<span class="w"> </span>cpu<span class="w"> </span><span class="se">\</span>
--input_file<span class="w"> </span>./datasets/dataset_gr1_nut_pouring.hdf5<span class="w"> </span><span class="se">\</span>
--output_file<span class="w"> </span>./datasets/dataset_annotated_gr1_nut_pouring.hdf5
</pre></div>
</div>
<div class="admonition warning">
<p class="admonition-title">Warning</p>
<p>There are multiple right eef annotations for this task. Annotations for subtasks for the same eef cannot have the same action index.
Make sure to annotate the right eef subtasks with different action indices.</p>
</div>
<p>To generate the dataset:</p>
<div class="highlight-bash notranslate"><div class="highlight"><pre><span></span>./isaaclab.sh<span class="w"> </span>-p<span class="w"> </span>scripts/imitation_learning/isaaclab_mimic/generate_dataset.py<span class="w"> </span><span class="se">\</span>
--task<span class="w"> </span>Isaac-NutPour-GR1T2-Pink-IK-Abs-Mimic-v0<span class="w"> </span><span class="se">\</span>
--visualizer<span class="w"> </span>kit<span class="w"> </span><span class="se">\</span>
--enable_cameras<span class="w"> </span><span class="se">\</span>
--device<span class="w"> </span>cpu<span class="w"> </span><span class="se">\</span>
--headless<span class="w"> </span><span class="se">\</span>
--generation_num_trials<span class="w"> </span><span class="m">1000</span><span class="w"> </span><span class="se">\</span>
--num_envs<span class="w"> </span><span class="m">5</span><span class="w"> </span><span class="se">\</span>
--input_file<span class="w"> </span>./datasets/dataset_annotated_gr1_nut_pouring.hdf5<span class="w"> </span><span class="se">\</span>
--output_file<span class="w"> </span>./datasets/generated_dataset_gr1_nut_pouring.hdf5
</pre></div>
</div>
</div>
</section>
<section id="id2">
<h3>Train a policy<a class="headerlink" href="#id2" title="Permalink to this heading">#</a></h3>
<p>Use <a class="reference external" href="https://robomimic.github.io/">Robomimic</a> to train a visuomotor BC agent for the task.</p>
<div class="highlight-bash notranslate"><div class="highlight"><pre><span></span>./isaaclab.sh<span class="w"> </span>-p<span class="w"> </span>scripts/imitation_learning/robomimic/train.py<span class="w"> </span><span class="se">\</span>
--task<span class="w"> </span>Isaac-NutPour-GR1T2-Pink-IK-Abs-v0<span class="w"> </span><span class="se">\</span>
--algo<span class="w"> </span>bc<span class="w"> </span><span class="se">\</span>
--normalize_training_actions<span class="w"> </span><span class="se">\</span>
--dataset<span class="w"> </span>./datasets/generated_dataset_gr1_nut_pouring.hdf5
</pre></div>
</div>
<p>The training script will normalize the actions in the dataset to the range [-1, 1].
The normalization parameters are saved in the model directory under <code class="docutils literal notranslate"><span class="pre">PATH_TO_MODEL_DIRECTORY/logs/normalization_params.txt</span></code>.
Record the normalization parameters for later use in the visualization step.</p>
<div class="admonition note">
<p class="admonition-title">Note</p>
<p>By default the trained models and logs will be saved to <code class="docutils literal notranslate"><span class="pre">IsaacLab/logs/robomimic</span></code>.</p>
</div>
<p>You can also post-train a <a class="reference external" href="https://github.com/NVIDIA/Isaac-GR00T">GR00T</a> foundation model to deploy a Vision-Language-Action policy for the task.</p>
<p>Please refer to the <a class="reference external" href="https://github.com/isaac-sim/IsaacLabEvalTasks/">IsaacLabEvalTasks</a> repository for more details.</p>
</section>
<section id="visualize-results-demo-2">
<span id="id3"></span><h3>Visualize the results<a class="headerlink" href="#visualize-results-demo-2" title="Permalink to this heading">#</a></h3>
<p>Visualize the results of the trained policy by running the following command, using the normalization parameters recorded in the prior training step:</p>
<div class="highlight-bash notranslate"><div class="highlight"><pre><span></span>./isaaclab.sh<span class="w"> </span>-p<span class="w"> </span>scripts/imitation_learning/robomimic/play.py<span class="w"> </span><span class="se">\</span>
--task<span class="w"> </span>Isaac-NutPour-GR1T2-Pink-IK-Abs-v0<span class="w"> </span><span class="se">\</span>
--visualizer<span class="w"> </span>kit<span class="w"> </span><span class="se">\</span>
--device<span class="w"> </span>cpu<span class="w"> </span><span class="se">\</span>
--enable_cameras<span class="w"> </span><span class="se">\</span>
--num_rollouts<span class="w"> </span><span class="m">50</span><span class="w"> </span><span class="se">\</span>
--horizon<span class="w"> </span><span class="m">350</span><span class="w"> </span><span class="se">\</span>
--norm_factor_min<span class="w"> </span>&lt;NORM_FACTOR_MIN&gt;<span class="w"> </span><span class="se">\</span>
--norm_factor_max<span class="w"> </span>&lt;NORM_FACTOR_MAX&gt;<span class="w"> </span><span class="se">\</span>
--checkpoint<span class="w"> </span>/PATH/TO/desired_model_checkpoint.pth
</pre></div>
</div>
<div class="admonition note">
<p class="admonition-title">Note</p>
<p>Change the <code class="docutils literal notranslate"><span class="pre">NORM_FACTOR</span></code> in the above command with the values generated in the training step.</p>
</div>
<div class="admonition tip">
<p class="admonition-title">Tip</p>
<p><strong>If you don’t see expected performance results:</strong> Test policies from various checkpoint epochs, not just the final one.
Policy performance can vary substantially across training, and intermediate checkpoints often yield better results.</p>
</div>
<figure class="align-center" id="id6">
<a class="reference internal image-reference" href="https://download.isaacsim.omniverse.nvidia.com/isaaclab/images/gr-1_nut_pouring_policy.gif"><img alt="GR-1 humanoid robot performing a pouring task" src="https://download.isaacsim.omniverse.nvidia.com/isaaclab/images/gr-1_nut_pouring_policy.gif" style="width: 100%;" /></a>
<figcaption>
<p><span class="caption-text">The trained visuomotor policy performing the pouring task in Isaac Lab.</span><a class="headerlink" href="#id6" title="Permalink to this image">#</a></p>
</figcaption>
</figure>
<div class="admonition note">
<p class="admonition-title">Note</p>
<p><strong>Expected Success Rates and Timings for Visuomotor Nut Pour GR1T2 Task</strong></p>
<ul class="simple">
<li><p>Success rate for data generation depends on the quality of human demonstrations (how well the user performs them) and dataset annotation quality. Both data generation and downstream policy success are sensitive to these factors and can show high variance. See <a class="reference internal" href="teleop_imitation.html#common-pitfalls-generating-data"><span class="std std-ref">Common Pitfalls when Generating Data</span></a> for tips to improve your dataset.</p></li>
<li><p>Data generation for 1000 demonstrations takes approximately 10 hours on a RTX ADA 6000.</p></li>
<li><p>Behavior Cloning (BC) policy success is typically 50-60% (evaluated on 50 rollouts) when trained on 1000 generated demonstrations for 600 epochs (default). Training takes approximately 15 hours on a RTX ADA 6000.</p></li>
<li><p><strong>Recommendation:</strong> Train for 600 epochs with 1000 generated demonstrations, and <strong>evaluate multiple checkpoints saved between the 300th and 600th epochs</strong> to select the best-performing policy. Testing various epochs is critical for achieving optimal performance.</p></li>
</ul>
</div>
</section>
</section>
<section id="demo-3-data-generation-and-policy-training-for-humanoid-robot-locomanipulation-with-unitree-g1">
<h2>Demo 3: Data Generation and Policy Training for Humanoid Robot Locomanipulation with Unitree G1<a class="headerlink" href="#demo-3-data-generation-and-policy-training-for-humanoid-robot-locomanipulation-with-unitree-g1" title="Permalink to this heading">#</a></h2>
<p>In this demo, we showcase the integration of locomotion and manipulation capabilities within a single humanoid robot system.
This locomanipulation environment enables data collection for complex tasks that combine navigation and object manipulation.
The demonstration follows a multi-step process: first, it generates pick and place tasks similar to Demo 1, then introduces
a navigation component that uses specialized scripts to generate scenes where the humanoid robot must move from point A to point B.
The robot picks up an object at the initial location (point A) and places it at the target destination (point B).</p>
<figure class="align-center">
<a class="reference internal image-reference" href="https://download.isaacsim.omniverse.nvidia.com/isaaclab/images/locomanipulation-g-1_steering_wheel_pick_place.gif"><img alt="G1 humanoid robot with locomanipulation performing a pick and place task" src="https://download.isaacsim.omniverse.nvidia.com/isaaclab/images/locomanipulation-g-1_steering_wheel_pick_place.gif" style="width: 100%;" /></a>
</figure>
<div class="admonition note">
<p class="admonition-title">Note</p>
<p><strong>Locomotion policy training</strong></p>
<p>The locomotion policy used in this integration example was trained using the <a class="reference external" href="https://github.com/nvidia-isaac/WBC-AGILE">AGILE</a> framework.
AGILE is an officially supported humanoid control training pipeline that leverages the manager based environment in Isaac Lab. It will also be
seamlessly integrated with other evaluation and deployment tools across Isaac products. This allows teams to rely on a single, maintained stack
covering all necessary infrastructure and tooling for policy training, with easy export to real-world deployment. The AGILE repository contains
updated pre-trained policies with separate upper and lower body policies for flexibtility. They have been verified in the real world and can be
directly deployed. Users can also train their own locomotion or whole-body control policies using the AGILE framework.</p>
</div>
<section id="generate-the-manipulation-dataset">
<h3>Generate the manipulation dataset<a class="headerlink" href="#generate-the-manipulation-dataset" title="Permalink to this heading">#</a></h3>
<p>The same data generation and policy training steps from Demo 1 can be applied to the G1 humanoid robot with locomanipulation capabilities.
This demonstration shows how to train a G1 robot to perform pick and place tasks with full-body locomotion and manipulation.</p>
<p>The process follows the same workflow as Demo 1, but uses the <code class="docutils literal notranslate"><span class="pre">Isaac-PickPlace-Locomanipulation-G1-Abs-v0</span></code> task environment.</p>
<p>Follow the same data collection, annotation, and generation process as demonstrated in Demo 1, but adapted for the G1 locomanipulation task.</p>
<div class="admonition hint">
<p class="admonition-title">Hint</p>
<p>If desired, data collection and annotation can be done using the same commands as the prior examples for validation of the dataset.</p>
<p>The G1 robot with locomanipulation capabilities combines full-body locomotion with manipulation to perform pick and place tasks.</p>
<p><strong>Note that the following commands are only for your reference and dataset validation purposes - they are not required for this demo.</strong></p>
<p>To collect demonstrations:</p>
<div class="highlight-bash notranslate"><div class="highlight"><pre><span></span>./isaaclab.sh<span class="w"> </span>-p<span class="w"> </span>scripts/tools/record_demos.py<span class="w"> </span><span class="se">\</span>
--device<span class="w"> </span>cpu<span class="w"> </span><span class="se">\</span>
--task<span class="w"> </span>Isaac-PickPlace-Locomanipulation-G1-Abs-v0<span class="w"> </span><span class="se">\</span>
--teleop_device<span class="w"> </span>handtracking<span class="w"> </span><span class="se">\</span>
--dataset_file<span class="w"> </span>./datasets/dataset_g1_locomanip.hdf5<span class="w"> </span><span class="se">\</span>
--num_demos<span class="w"> </span><span class="m">5</span>
</pre></div>
</div>
<div class="admonition note">
<p class="admonition-title">Note</p>
<p>Depending on how the Apple Vision Pro app was initialized, the hands of the operator might be very far up or far down compared to the hands of the G1 robot. If this is the case, you can click <strong>Stop AR</strong> in the AR tab in Isaac Lab, and move the AR Anchor prim. Adjust it down to bring the hands of the operator lower, and up to bring them higher. Click <strong>Start AR</strong> to resume teleoperation session. Make sure to match the hands of the robot before clicking <strong>Play</strong> in the Apple Vision Pro, otherwise there will be an undesired large force generated initially.</p>
</div>
<p>You can replay the collected demonstrations by running:</p>
<div class="highlight-bash notranslate"><div class="highlight"><pre><span></span>./isaaclab.sh<span class="w"> </span>-p<span class="w"> </span>scripts/tools/replay_demos.py<span class="w"> </span><span class="se">\</span>
--device<span class="w"> </span>cpu<span class="w"> </span><span class="se">\</span>
--task<span class="w"> </span>Isaac-PickPlace-Locomanipulation-G1-Abs-v0<span class="w"> </span><span class="se">\</span>
--dataset_file<span class="w"> </span>./datasets/dataset_g1_locomanip.hdf5
</pre></div>
</div>
<p>To annotate the demonstrations:</p>
<div class="highlight-bash notranslate"><div class="highlight"><pre><span></span>./isaaclab.sh<span class="w"> </span>-p<span class="w"> </span>scripts/imitation_learning/isaaclab_mimic/annotate_demos.py<span class="w"> </span><span class="se">\</span>
--device<span class="w"> </span>cpu<span class="w"> </span><span class="se">\</span>
--task<span class="w"> </span>Isaac-Locomanipulation-G1-Abs-Mimic-v0<span class="w"> </span><span class="se">\</span>
--input_file<span class="w"> </span>./datasets/dataset_g1_locomanip.hdf5<span class="w"> </span><span class="se">\</span>
--output_file<span class="w"> </span>./datasets/dataset_annotated_g1_locomanip.hdf5
</pre></div>
</div>
</div>
<p>If you skipped the prior collection and annotation step, download the pre-recorded annotated dataset <code class="docutils literal notranslate"><span class="pre">dataset_annotated_g1_locomanip.hdf5</span></code> from
here: <a class="reference external" href="https://omniverse-content-staging.s3-us-west-2.amazonaws.com/Assets/Isaac/6.0/Isaac/IsaacLab/Mimic/pick_place_datasets/dataset_annotated_g1_locomanip.hdf5">[Annotated G1 Dataset]</a>.
Place the file under <code class="docutils literal notranslate"><span class="pre">IsaacLab/datasets</span></code> and run the following command to generate a new dataset with 1000 demonstrations.</p>
<div class="highlight-bash notranslate"><div class="highlight"><pre><span></span>./isaaclab.sh<span class="w"> </span>-p<span class="w"> </span>scripts/imitation_learning/isaaclab_mimic/generate_dataset.py<span class="w"> </span><span class="se">\</span>
--device<span class="w"> </span>cpu<span class="w"> </span>--headless<span class="w"> </span>--num_envs<span class="w"> </span><span class="m">20</span><span class="w"> </span>--generation_num_trials<span class="w"> </span><span class="m">1000</span><span class="w"> </span><span class="se">\</span>
--input_file<span class="w"> </span>./datasets/dataset_annotated_g1_locomanip.hdf5<span class="w"> </span>--output_file<span class="w"> </span>./datasets/generated_dataset_g1_locomanip.hdf5
</pre></div>
</div>
</section>
<section id="train-a-manipulation-only-policy">
<h3>Train a manipulation-only policy<a class="headerlink" href="#train-a-manipulation-only-policy" title="Permalink to this heading">#</a></h3>
<p>At this point you can train a policy that only performs manipulation tasks using the generated dataset:</p>
<div class="highlight-bash notranslate"><div class="highlight"><pre><span></span>./isaaclab.sh<span class="w"> </span>-p<span class="w"> </span>scripts/imitation_learning/robomimic/train.py<span class="w"> </span><span class="se">\</span>
--task<span class="w"> </span>Isaac-PickPlace-Locomanipulation-G1-Abs-v0<span class="w"> </span>--algo<span class="w"> </span>bc<span class="w"> </span><span class="se">\</span>
--normalize_training_actions<span class="w"> </span><span class="se">\</span>
--dataset<span class="w"> </span>./datasets/generated_dataset_g1_locomanip.hdf5
</pre></div>
</div>
</section>
<section id="id4">
<h3>Visualize the results<a class="headerlink" href="#id4" title="Permalink to this heading">#</a></h3>
<p>Visualize the trained policy performance:</p>
<div class="highlight-bash notranslate"><div class="highlight"><pre><span></span>./isaaclab.sh<span class="w"> </span>-p<span class="w"> </span>scripts/imitation_learning/robomimic/play.py<span class="w"> </span><span class="se">\</span>
--device<span class="w"> </span>cpu<span class="w"> </span><span class="se">\</span>
--task<span class="w"> </span>Isaac-PickPlace-Locomanipulation-G1-Abs-v0<span class="w"> </span><span class="se">\</span>
--num_rollouts<span class="w"> </span><span class="m">50</span><span class="w"> </span><span class="se">\</span>
--horizon<span class="w"> </span><span class="m">400</span><span class="w"> </span><span class="se">\</span>
--norm_factor_min<span class="w"> </span>&lt;NORM_FACTOR_MIN&gt;<span class="w"> </span><span class="se">\</span>
--norm_factor_max<span class="w"> </span>&lt;NORM_FACTOR_MAX&gt;<span class="w"> </span><span class="se">\</span>
--checkpoint<span class="w"> </span>/PATH/TO/desired_model_checkpoint.pth
</pre></div>
</div>
<div class="admonition note">
<p class="admonition-title">Note</p>
<p>Change the <code class="docutils literal notranslate"><span class="pre">NORM_FACTOR</span></code> in the above command with the values generated in the training step.</p>
</div>
<div class="admonition tip">
<p class="admonition-title">Tip</p>
<p><strong>If you don’t see expected performance results:</strong> Always test policies from various checkpoint epochs.
Different epochs can produce significantly different results, so evaluate multiple checkpoints to find the optimal model.</p>
</div>
<figure class="align-center" id="id7">
<a class="reference internal image-reference" href="https://download.isaacsim.omniverse.nvidia.com/isaaclab/images/locomanipulation-g-1_steering_wheel_pick_place.gif"><img alt="G1 humanoid robot performing a pick and place task" src="https://download.isaacsim.omniverse.nvidia.com/isaaclab/images/locomanipulation-g-1_steering_wheel_pick_place.gif" style="width: 100%;" /></a>
<figcaption>
<p><span class="caption-text">The trained policy performing the pick and place task in Isaac Lab.</span><a class="headerlink" href="#id7" title="Permalink to this image">#</a></p>
</figcaption>
</figure>
<div class="admonition note">
<p class="admonition-title">Note</p>
<p><strong>Expected Success Rates and Timings for Locomanipulation Pick and Place Task</strong></p>
<ul class="simple">
<li><p>Success rate for data generation depends on the quality of human demonstrations (how well the user performs them) and dataset annotation quality. Both data generation and downstream policy success are sensitive to these factors and can show high variance. See <a class="reference internal" href="teleop_imitation.html#common-pitfalls-generating-data"><span class="std std-ref">Common Pitfalls when Generating Data</span></a> for tips to improve your dataset.</p></li>
<li><p>Data generation success for this task is typically 65-82% over 1000 demonstrations, taking 18-40 minutes depending on GPU hardware and success rate (18 minutes on a RTX ADA 6000 &#64; 82% success rate).</p></li>
<li><p>Behavior Cloning (BC) policy success is typically 75-85% (evaluated on 50 rollouts) when trained on 1000 generated demonstrations for 2000 epochs (default), depending on demonstration quality. Training takes approximately 40 minutes on a RTX ADA 6000.</p></li>
<li><p><strong>Recommendation:</strong> Train for 2000 epochs with 1000 generated demonstrations, and <strong>evaluate multiple checkpoints saved between the 1000th and 2000th epochs</strong> to select the best-performing policy. Testing various epochs is essential for finding optimal performance.</p></li>
</ul>
</div>
</section>
<section id="generate-the-dataset-with-manipulation-and-point-to-point-navigation">
<h3>Generate the dataset with manipulation and point-to-point navigation<a class="headerlink" href="#generate-the-dataset-with-manipulation-and-point-to-point-navigation" title="Permalink to this heading">#</a></h3>
<p>To create a comprehensive locomanipulation dataset that combines both manipulation and navigation capabilities, you can generate a navigation dataset using the manipulation dataset from the previous step as input.</p>
<figure class="align-center" id="id8">
<a class="reference internal image-reference" href="https://download.isaacsim.omniverse.nvidia.com/isaaclab/images/disjoint_navigation.gif"><img alt="G1 humanoid robot combining navigation with locomanipulation" src="https://download.isaacsim.omniverse.nvidia.com/isaaclab/images/disjoint_navigation.gif" style="width: 100%;" /></a>
<figcaption>
<p><span class="caption-text">G1 humanoid robot performing locomanipulation with navigation capabilities.</span><a class="headerlink" href="#id8" title="Permalink to this image">#</a></p>
</figcaption>
</figure>
<p>The locomanipulation dataset generation process takes the previously generated manipulation dataset and creates scenarios where the robot must navigate from one location to another while performing manipulation tasks. This creates a more complex dataset that includes both locomotion and manipulation behaviors.</p>
<p>To generate the locomanipulation dataset, use the following command:</p>
<div class="highlight-bash notranslate"><div class="highlight"><pre><span></span>./isaaclab.sh<span class="w"> </span>-p<span class="w"> </span><span class="se">\</span>
<span class="w">    </span>scripts/imitation_learning/locomanipulation_sdg/generate_data.py<span class="w"> </span><span class="se">\</span>
<span class="w">    </span>--device<span class="w"> </span>cpu<span class="w"> </span><span class="se">\</span>
<span class="w">    </span>--kit_args<span class="o">=</span><span class="s2">&quot;--enable isaacsim.replicator.mobility_gen&quot;</span><span class="w"> </span><span class="se">\</span>
<span class="w">    </span>--task<span class="o">=</span><span class="s2">&quot;Isaac-G1-SteeringWheel-Locomanipulation&quot;</span><span class="w"> </span><span class="se">\</span>
<span class="w">    </span>--dataset<span class="w"> </span>./datasets/generated_dataset_g1_locomanip.hdf5<span class="w"> </span><span class="se">\</span>
<span class="w">    </span>--num_runs<span class="w"> </span><span class="m">1</span><span class="w"> </span><span class="se">\</span>
<span class="w">    </span>--lift_step<span class="w"> </span><span class="m">60</span><span class="w"> </span><span class="se">\</span>
<span class="w">    </span>--navigate_step<span class="w"> </span><span class="m">130</span><span class="w"> </span><span class="se">\</span>
<span class="w">    </span>--output_file<span class="w"> </span>./datasets/generated_dataset_g1_locomanipulation_sdg.hdf5<span class="w"> </span><span class="se">\</span>
<span class="w">    </span>--enable_cameras
</pre></div>
</div>
<div class="admonition note">
<p class="admonition-title">Note</p>
<p>The input dataset (<code class="docutils literal notranslate"><span class="pre">--dataset</span></code>) should be the manipulation dataset generated in the previous step. You can specify any output filename using the <code class="docutils literal notranslate"><span class="pre">--output_file_name</span></code> parameter.</p>
</div>
<p>The key parameters for locomanipulation dataset generation are:</p>
<ul class="simple">
<li><p><code class="docutils literal notranslate"><span class="pre">--lift_step</span> <span class="pre">70</span></code>: Number of steps for the lifting phase of the manipulation task.  This should mark the point immediately after the robot has grasped the object.</p></li>
<li><p><code class="docutils literal notranslate"><span class="pre">--navigate_step</span> <span class="pre">120</span></code>: Number of steps for the navigation phase between locations.  This should make the point where the robot has lifted the object and is ready to walk.</p></li>
<li><p><code class="docutils literal notranslate"><span class="pre">--output_file</span></code>: Name of the output dataset file</p></li>
</ul>
<p>This process creates a dataset where the robot performs the manipulation task at different locations, requiring it to navigate between points while maintaining the learned manipulation behaviors. The resulting dataset can be used to train policies that combine both locomotion and manipulation capabilities.</p>
<div class="admonition note">
<p class="admonition-title">Note</p>
<p>You can visualize the robot trajectory results with the following script command:</p>
<div class="highlight-bash notranslate"><div class="highlight"><pre><span></span>./isaaclab.sh<span class="w"> </span>-p<span class="w"> </span>scripts/imitation_learning/locomanipulation_sdg/plot_navigation_trajectory.py<span class="w"> </span>--input_file<span class="w"> </span>datasets/generated_dataset_g1_locomanipulation_sdg.hdf5<span class="w"> </span>--output_dir<span class="w"> </span>/PATH/TO/DESIRED_OUTPUT_DIR
</pre></div>
</div>
</div>
<p>The data generated from this locomanipulation pipeline can also be used to finetune an imitation learning policy using GR00T N1.5.  To do this,
you may convert the generated dataset to LeRobot format as expected by GR00T N1.5, and then run the finetuning script provided
in the GR00T N1.5 repository.  An example closed-loop policy rollout is shown in the video below:</p>
<figure class="align-center" id="id9">
<a class="reference internal image-reference" href="https://download.isaacsim.omniverse.nvidia.com/isaaclab/images/locomanipulation_sdg_disjoint_nav_groot_policy_4x.gif"><img alt="Simulation rollout of GR00T N1.5 policy finetuned for locomanipulation" src="https://download.isaacsim.omniverse.nvidia.com/isaaclab/images/locomanipulation_sdg_disjoint_nav_groot_policy_4x.gif" style="width: 100%;" /></a>
<figcaption>
<p><span class="caption-text">Simulation rollout of GR00T N1.5 policy finetuned for locomanipulation.</span><a class="headerlink" href="#id9" title="Permalink to this image">#</a></p>
</figcaption>
</figure>
<p>The policy shown above uses the camera image, hand poses, hand joint positions, object pose, and base goal pose as inputs.
The output of the model is the target base velocity, hand poses, and hand joint positions for the next several timesteps.</p>
</section>
</section>
</section>


                </article>
              

              
              
              
              
                <footer class="prev-next-footer d-print-none">
                  
<div class="prev-next-area">
    <a class="left-prev"
       href="teleop_imitation.html"
       title="previous page">
      <i class="fa-solid fa-angle-left"></i>
      <div class="prev-next-info">
        <p class="prev-next-subtitle">previous</p>
        <p class="prev-next-title">Teleoperation and Imitation Learning with Isaac Lab Mimic</p>
      </div>
    </a>
    <a class="right-next"
       href="augmented_imitation.html"
       title="next page">
      <div class="prev-next-info">
        <p class="prev-next-subtitle">next</p>
        <p class="prev-next-title">Augmented Imitation Learning</p>
      </div>
      <i class="fa-solid fa-angle-right"></i>
    </a>
</div>
                </footer>
              
            </div>
            
            
              
                <dialog id="pst-secondary-sidebar-modal"></dialog>
                <div id="pst-secondary-sidebar" class="bd-sidebar-secondary bd-toc"><div class="sidebar-secondary-items sidebar-secondary__inner">


  <div class="sidebar-secondary-item">
  <div class="page-toc tocsection onthispage">
    <i class="fa-solid fa-list"></i> Contents
  </div>
  <nav class="bd-toc-nav page-toc">
    <ul class="visible nav section-nav flex-column">
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#demo-1-data-generation-and-policy-training-for-a-humanoid-robot">Demo 1: Data Generation and Policy Training for a Humanoid Robot</a><ul class="nav section-nav flex-column">
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#optional-collect-and-annotate-demonstrations">Optional: Collect and annotate demonstrations</a><ul class="nav section-nav flex-column">
<li class="toc-h4 nav-item toc-entry"><a class="reference internal nav-link" href="#collect-human-demonstrations">Collect human demonstrations</a></li>
<li class="toc-h4 nav-item toc-entry"><a class="reference internal nav-link" href="#annotate-the-demonstrations">Annotate the demonstrations</a></li>
</ul>
</li>
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#generate-the-dataset">Generate the dataset</a></li>
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#train-a-policy">Train a policy</a></li>
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#visualize-the-results">Visualize the results</a></li>
</ul>
</li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#demo-2-visuomotor-policy-for-a-humanoid-robot">Demo 2: Visuomotor Policy for a Humanoid Robot</a><ul class="nav section-nav flex-column">
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#download-the-dataset">Download the Dataset</a></li>
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#id2">Train a policy</a></li>
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#visualize-results-demo-2">Visualize the results</a></li>
</ul>
</li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#demo-3-data-generation-and-policy-training-for-humanoid-robot-locomanipulation-with-unitree-g1">Demo 3: Data Generation and Policy Training for Humanoid Robot Locomanipulation with Unitree G1</a><ul class="nav section-nav flex-column">
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#generate-the-manipulation-dataset">Generate the manipulation dataset</a></li>
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#train-a-manipulation-only-policy">Train a manipulation-only policy</a></li>
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#id4">Visualize the results</a></li>
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#generate-the-dataset-with-manipulation-and-point-to-point-navigation">Generate the dataset with manipulation and point-to-point navigation</a></li>
</ul>
</li>
</ul>
  </nav></div>

</div></div>
              
            
          </div>
          <footer class="bd-footer-content">
            
<div class="bd-footer-content__inner container">
  
  <div class="footer-item">
    
<p class="component-author">
By The Isaac Lab Project Developers.
</p>

  </div>
  
  <div class="footer-item">
    

  <p class="copyright">
    
      © Copyright 2022-2025, The Isaac Lab Project Developers..
      <br/>
    
  </p>

  </div>
  
  <div class="footer-item">
    <p class="last-updated">
  Last updated on Feb 26, 2026.
  <br/>
</p>
  </div>
  
  <div class="footer-item">
    
  </div>
  
</div>
          </footer>
        

      </main>
    </div>
  </div>
  
  <!-- Scripts loaded after <body> so the DOM is not blocked -->
  <script defer src="../../../_static/scripts/bootstrap.js?digest=8878045cc6db502f8baf"></script>
<script defer src="../../../_static/scripts/pydata-sphinx-theme.js?digest=8878045cc6db502f8baf"></script>

  <footer class="bd-footer">
  </footer>
  </body>
</html>